{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  warnings,                   \\\n",
    "        calendar,                   \\\n",
    "        pandas as pd,               \\\n",
    "        numpy as np,                \\\n",
    "        requests as rt,             \\\n",
    "        hydrobr as hbr,             \\\n",
    "        xml.etree.ElementTree as ET\n",
    "from typing import List\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "# Desativar as mensagens de 'warning' que ficam poluindo o output de alguns trechos de código.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(file_name : str,\n",
    "                   separator : str = \"\\t\",\n",
    "                   adjust : bool = True,\n",
    "                   date_column : str = \"ds\"\n",
    "                   ) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_csv(file_name, sep=separator, index_col=date_column, header=0, parse_dates=[date_column])\n",
    "\n",
    "    if adjust:\n",
    "        df = df.resample('D').first() # deixando a série contínua numa base diária\n",
    "\n",
    "    # Deixando ajustado para usar com as libs Nixtla\n",
    "    df['unique_id'] = 1\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def get_telemetrica(codEstacao : str,\n",
    "                    dataInicio : str,\n",
    "                    dataFim : str,\n",
    "                    save : bool = False) -> pd.DataFrame:\n",
    "    # 1. Fazer a requisião ao servidor e pegar a árvore e a raiz dos dados \n",
    "    params = {'codEstacao':codEstacao, 'dataInicio':dataInicio, 'dataFim':dataFim}\n",
    "    server = 'http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos'\n",
    "    response = rt.get(server, params)\n",
    "    tree = ET.ElementTree(ET.fromstring(response.content))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # 2. Iteração dentro dos elementos do XML procurando os dados que são disponibilizados para a estação\n",
    "    list_vazao = []\n",
    "    list_data = []\n",
    "    list_cota = []\n",
    "    list_chuva = []\n",
    "\n",
    "    for i in root.iter('DadosHidrometereologicos'):\n",
    "\n",
    "        data = i.find('DataHora').text\n",
    "        try:\n",
    "            vazao = float(i.find('Vazao').text)\n",
    "        except TypeError:\n",
    "            vazao = i.find('Vazao').text\n",
    "\n",
    "        try:\n",
    "            cota = float(i.find('Nivel').text)\n",
    "        except TypeError:\n",
    "            cota = i.find('Nivel').text\n",
    "\n",
    "        try:\n",
    "            chuva = float(i.find('Chuva').text)\n",
    "        except TypeError:\n",
    "            chuva = i.find('Chuva').text\n",
    "\n",
    "        list_vazao.append(vazao)\n",
    "        list_data.append(data)\n",
    "        list_cota.append(cota)\n",
    "        list_chuva.append(chuva)\n",
    "\n",
    "    df = pd.DataFrame([list_data, list_cota, list_chuva, list_vazao]).transpose()\n",
    "    df.columns = ['Data', 'Cota', 'Chuva', 'Vazao']\n",
    "    df = df.sort_values(by='Data')\n",
    "    df = df.set_index('Data')\n",
    "    \n",
    "    if save == True:\n",
    "        df.to_excel(codEstacao+'_dados_tele.xlsx')\n",
    "    \n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def get_convencional(codEstacao : str,\n",
    "                     dataInicio : str,\n",
    "                     dataFim : str,\n",
    "                     tipoDados : int,\n",
    "                     nivelConsistencia : int,\n",
    "                     save : bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Série Histórica estação - HIDRO.\n",
    "        codEstacao : Código Plu ou Flu\n",
    "        dataInicio : <YYYY-mm-dd>\n",
    "        dataFim : Caso não preenchido, trará até o último dado mais recente armazenado\n",
    "        tipoDados : 1-Cotas, 2-Chuvas ou 3-Vazões\n",
    "        nivelConsistencia : 1-Bruto ou 2-Consistido\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Fazer a requisião ao servidor e pegar a árvore e a raiz dos dados \n",
    "    params = {'codEstacao':codEstacao, 'dataInicio':dataInicio, 'dataFim':dataFim,\n",
    "              'tipoDados':tipoDados, 'nivelConsistencia':nivelConsistencia}\n",
    "    \n",
    "    server = 'http://telemetriaws1.ana.gov.br/ServiceANA.asmx/HidroSerieHistorica'\n",
    "    response = rt.get(server, params)\n",
    "    tree = ET.ElementTree(ET.fromstring(response.content))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # 2. Iteração dentro dos elementos do XML procurando os dados que são disponibilizados para a estação\n",
    "    list_data = []\n",
    "    list_consistenciaF = []\n",
    "    list_month_dates = []\n",
    "\n",
    "    for i in root.iter('SerieHistorica'):\n",
    "\n",
    "        consistencia = i.find('NivelConsistencia').text\n",
    "        date = i.find('DataHora').text\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        last_day = calendar.monthrange(date.year, date.month)[1]\n",
    "        month_dates = [date + timedelta(days=i) for i in range(last_day)]\n",
    "        content = []\n",
    "        list_consistencia = []\n",
    "\n",
    "        for day in range(last_day):\n",
    "            if tipoDados == 1:\n",
    "                value = f'Cota{day+1:02d}'\n",
    "            if tipoDados == 2:\n",
    "                value = f'Chuva{day+1:02d}'\n",
    "            if tipoDados == 3:\n",
    "                value = f'Vazao{day+1:02d}'\n",
    "            \n",
    "            try:\n",
    "                content.append(float(i.find(value).text))\n",
    "                list_consistencia.append(int(consistencia))\n",
    "            except TypeError:\n",
    "                content.append(i.find(value).text)\n",
    "                list_consistencia.append(int(consistencia))\n",
    "            except AttributeError:\n",
    "                content.append(None)\n",
    "                list_consistencia.append(int(consistencia))\n",
    "        \n",
    "        list_data += content\n",
    "        list_consistenciaF += list_consistencia\n",
    "        list_month_dates += month_dates\n",
    "    df = pd.DataFrame([list_month_dates, list_consistenciaF, list_data]).transpose()\n",
    "\n",
    "    if tipoDados == 1:\n",
    "        df.columns = ['Data','Consistencia','Cota']\n",
    "    elif tipoDados == 2:\n",
    "        df.columns = ['Data','Consistencia','Chuva']\n",
    "    else: # Vazão\n",
    "        df.columns = ['Data','Consistencia','Vazao']\n",
    "    \n",
    "    df = df.sort_values(by='Data')\n",
    "    df = df.set_index('Data')\n",
    "\n",
    "    if save == True:\n",
    "        df.to_excel(codEstacao + '_dados_conv.xlsx')\n",
    "    \n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def gerar_dados_tele(estacao_principal : str,\n",
    "                    outras_estacoes : List[str],\n",
    "                    nome_arq : str,\n",
    "                    dt_inicio : str,\n",
    "                    dt_fim : str,\n",
    "                    salvar : bool = False) -> None:\n",
    "    \"\"\"\n",
    "            Este método vai pegar o código da 'estacao_principal' (que o usuário já sabe previamente que é uma telemétrica), baixar os dados da estação\n",
    "        e concatenar (outer join) com os dados das outras estações telemétricas. Neste método já será realizada a conversão dos dados de 'object' para\n",
    "        os tipos de acordo, ou seja, 'float' para os campos numéricos e 'datetime' para os campos de datahora.\n",
    "            Como o desejo do trabalho é lidar com dados diários, já aproveita pra fazer a agregação dos dados desta maneira também.\n",
    "            Após tudo isso, salva num arquivo xlsx para usos posteriores.\n",
    "\n",
    "        Parâmetros:\n",
    "            estacao_principal : str,\n",
    "            outras_estacoes : List[str],\n",
    "            nome_arq : str,\n",
    "            dt_inicio : str = 'YYYY-mm-dd',\n",
    "            dt_fim : str = 'YYYY-mm-dd',\n",
    "            salvar : bool = True|False\n",
    "    \"\"\"\n",
    "\n",
    "    df_result = get_telemetrica(codEstacao=estacao_principal, dataInicio=dt_inicio, dataFim=dt_fim)\n",
    "\n",
    "    df_result.index = pd.to_datetime(df_result.index)\n",
    "    df_result.Cota = pd.to_numeric(df_result.Cota, errors='coerce')\n",
    "    df_result.Chuva = pd.to_numeric(df_result.Chuva, errors='coerce')\n",
    "    df_result.Vazao = pd.to_numeric(df_result.Vazao, errors='coerce')\n",
    "\n",
    "    df_result = df_result.resample('D').agg({'Cota': 'mean', 'Chuva': 'sum', 'Vazao': 'mean'})\n",
    "\n",
    "    df_result.columns = ['t_ct_'+str(estacao_principal), 't_cv_'+str(estacao_principal), 't_vz_'+str(estacao_principal)]\n",
    "\n",
    "    # Agora que já tenho os dados da estação que considero principal na análise (target)\n",
    "    #   vou agregar com os dados das demais estações\n",
    "\n",
    "    if outras_estacoes is not None:\n",
    "        for e in outras_estacoes:\n",
    "            df_temp = get_telemetrica(codEstacao=e, dataInicio=dt_inicio, dataFim=dt_fim)\n",
    "\n",
    "            # Convertendo os dados\n",
    "            df_temp.index = pd.to_datetime(df_temp.index)\n",
    "            df_temp.Cota = pd.to_numeric(df_temp.Cota, errors='coerce')\n",
    "            df_temp.Chuva = pd.to_numeric(df_temp.Chuva, errors='coerce')\n",
    "            df_temp.Vazao = pd.to_numeric(df_temp.Vazao, errors='coerce')\n",
    "\n",
    "            # Para as telemétricas já agrego aqui mesmo\n",
    "            df_temp = df_temp.resample('D').agg({'Cota': 'mean', 'Chuva': 'sum', 'Vazao': 'mean'})\n",
    "\n",
    "            # Ajeito os nomes das colunas pra conter de qual estacao os dado veio\n",
    "            df_temp.columns = ['t_ct_'+e, 't_cv_'+e, 't_vz_'+e]\n",
    "\n",
    "            df_result = pd.concat([df_result, df_temp], axis=1)\n",
    "\n",
    "    if salvar:\n",
    "        df_result.to_excel(nome_arq+'_dados_tele.xlsx')\n",
    "# ============================================================================================ #\n",
    "def gerar_dados_conv(estacao_principal : str,\n",
    "                    outras_estacoes : List[str],\n",
    "                    nome_arq : str,\n",
    "                    dt_inicio : str,\n",
    "                    dt_fim : str,\n",
    "                    tp_dados : int,\n",
    "                    nvl_consistencia : str,\n",
    "                    drop_consistencia : bool = True, # Remover a coluna \"NivelConsistência\". Ela será irrelevante, até segunda ordem.\n",
    "                    salvar : bool = False) -> None:\n",
    "    \"\"\"\n",
    "            Este método vai pegar o código da 'estacao_principal' (que o usuário já sabe previamente que é uma convencional), baixar os dados da estação\n",
    "        e concatenar (outer join) com os dados das outras estações convencionais. Neste método já será realizada a conversão dos dados de 'object' para\n",
    "        os tipos de acordo, ou seja, 'float' para os campos numéricos e 'datetime' para os campos de datahora.\n",
    "            Como o desejo do trabalho é lidar com dados diários, já aproveita pra fazer a agregação dos dados desta maneira também.\n",
    "            Após tudo isso, salva num arquivo xlsx para usos posteriores.\n",
    "\n",
    "        Parâmetros:\n",
    "            estacao_principal : str,\n",
    "            outras_estacoes : List[str],\n",
    "            nome_arq : str,\n",
    "            dt_inicio : str = 'YYYY-mm-dd',\n",
    "            dt_fim : str = 'YYYY-mm-dd',\n",
    "            tp_dados : int (1-cota | 2-chuva | 3-vazao),\n",
    "            nvl_consistencia : int (1-bruto | 2-consistido),\n",
    "            drop_consistencia : bool = True, (Remover a coluna \"NivelConsistência\". Ela será irrelevante, até segunda ordem)\n",
    "            salvar : bool = False\n",
    "    \"\"\"\n",
    "\n",
    "    df_result = get_convencional(codEstacao=estacao_principal, dataInicio=dt_inicio, dataFim=dt_fim, tipoDados=tp_dados, nivelConsistencia=nvl_consistencia)\n",
    "\n",
    "    df_result.index = pd.to_datetime(df_result.index)\n",
    "\n",
    "    if drop_consistencia:\n",
    "        df_result.drop(columns=['Consistencia'], inplace=True)\n",
    "\n",
    "    if tp_dados == 1:\n",
    "        df_result.Cota = pd.to_numeric(df_result.Cota, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Cota': 'mean'})\n",
    "        df_result.columns = ['c_ct_'+str(estacao_principal)]\n",
    "    elif tp_dados == 2:\n",
    "        df_result.Chuva = pd.to_numeric(df_result.Chuva, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Chuva': 'sum'})\n",
    "        df_result.columns = ['c_cv_'+str(estacao_principal)]\n",
    "    else: # Vazão\n",
    "        df_result.Vazao = pd.to_numeric(df_result.Vazao, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Vazao': 'mean'})\n",
    "        df_result.columns = ['c_vz_'+str(estacao_principal)]\n",
    "\n",
    "    # Agora que já tenho os dados da estação que considero principal na análise (target)\n",
    "    #   vou agregar com os dados das demais estações\n",
    "\n",
    "    for e in outras_estacoes:\n",
    "        df_temp = get_convencional(codEstacao=e, dataInicio=dt_inicio, dataFim=dt_fim, tipoDados=tp_dados, nivelConsistencia=nvl_consistencia)\n",
    "\n",
    "        # Convertendo os dados\n",
    "        df_temp.index = pd.to_datetime(df_temp.index)\n",
    "\n",
    "        if drop_consistencia:\n",
    "            df_temp.drop(columns=['Consistencia'], inplace=True)\n",
    "\n",
    "        if tp_dados == 1:\n",
    "            df_temp.Cota = pd.to_numeric(df_temp.Cota, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Cota': 'mean'})\n",
    "            df_temp.columns = ['c_ct_'+str(e)]\n",
    "        elif tp_dados == 2:\n",
    "            df_temp.Chuva = pd.to_numeric(df_temp.Chuva, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Chuva': 'sum'})\n",
    "            df_temp.columns = ['c_cv_'+str(e)]\n",
    "        else:\n",
    "            df_temp.Vazao = pd.to_numeric(df_temp.Vazao, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Vazao': 'mean'})\n",
    "            df_temp.columns = ['c_vz_'+str(e)]\n",
    "\n",
    "        df_result = pd.concat([df_result, df_temp], axis=1)\n",
    "\n",
    "    if salvar:\n",
    "        if tp_dados == 1:\n",
    "            df_result.to_excel(nome_arq + '_dados_cota_conv.xlsx')\n",
    "        elif tp_dados == 2:\n",
    "            df_result.to_excel(nome_arq + '_dados_chuva_conv.xlsx')\n",
    "        else:\n",
    "            df_result.to_excel(nome_arq + '_dados_vazao_conv.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixo Rio Grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando os dados das estações que serão utilizadas no trabalho\n",
    "# As estações foram selecionadas a partir do sistema Data Rhama\n",
    "# Aqui eu baixo os dados e salvo localmente\n",
    "# >>>>>>>>>>>>> SÓ PRECISA FAZER ISSO UMA VEZ, POR ISSO O CÓDIGO FICA COMENTADO DEPOIS DE RODAR!!!! <<<<<<<<<<<<<\n",
    "\n",
    "estacao_principal = '62020080'\n",
    "outras_estacoes = ['61998080', '01950006', '02050001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemétricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4819it [00:03, 1372.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City-State</th>\n",
       "      <th>Origem</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIO PRETO DA EVA</td>\n",
       "      <td>00259004</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>15</td>\n",
       "      <td>RIO PRETO DA EVA-AM</td>\n",
       "      <td>Açudes Semiárido</td>\n",
       "      <td>00001 - ANA - Agência Nacional de Águas</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.7003</td>\n",
       "      <td>-59.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UHE BELO MONTE BR230</td>\n",
       "      <td>00351004</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>VITÓRIA DO XINGU-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>33.00</td>\n",
       "      <td>-3.1267</td>\n",
       "      <td>-51.7906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UHE BELO MONTE SÍTIO PIMENTAL</td>\n",
       "      <td>00351005</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>VITÓRIA DO XINGU-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>110.00</td>\n",
       "      <td>-3.3758</td>\n",
       "      <td>-51.9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UHE BELO MONTE VISTA ALEGRE</td>\n",
       "      <td>00352009</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>ALTAMIRA-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>125.00</td>\n",
       "      <td>-3.1186</td>\n",
       "      <td>-52.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UHE BELO MONTE SÃO FRANCISCO</td>\n",
       "      <td>00352010</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>ALTAMIRA-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-3.2533</td>\n",
       "      <td>-52.3489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name      Code Status SubBasin  \\\n",
       "1               RIO PRETO DA EVA  00259004  Ativo       15   \n",
       "2           UHE BELO MONTE BR230  00351004  Ativo       18   \n",
       "3  UHE BELO MONTE SÍTIO PIMENTAL  00351005  Ativo       18   \n",
       "4    UHE BELO MONTE VISTA ALEGRE  00352009  Ativo       18   \n",
       "5   UHE BELO MONTE SÃO FRANCISCO  00352010  Ativo       18   \n",
       "\n",
       "            City-State            Origem  \\\n",
       "1  RIO PRETO DA EVA-AM  Açudes Semiárido   \n",
       "2  VITÓRIA DO XINGU-PA    Setor Elétrico   \n",
       "3  VITÓRIA DO XINGU-PA    Setor Elétrico   \n",
       "4          ALTAMIRA-PA    Setor Elétrico   \n",
       "5          ALTAMIRA-PA    Setor Elétrico   \n",
       "\n",
       "                                 Responsible Elevation  Latitude  Longitude  \n",
       "1   00001 - ANA - Agência Nacional de Águas       0.00   -2.7003   -59.6997  \n",
       "2  00594 - NORTE ENERGIA - Norte Energia S.A     33.00   -3.1267   -51.7906  \n",
       "3  00594 - NORTE ENERGIA - Norte Energia S.A    110.00   -3.3758   -51.9403  \n",
       "4  00594 - NORTE ENERGIA - Norte Energia S.A    125.00   -3.1186   -52.2525  \n",
       "5  00594 - NORTE ENERGIA - Norte Energia S.A    124.00   -3.2533   -52.3489  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica, como é o caso aqui\n",
    "\n",
    "lista_estacoes = hbr.get_data.ANA.list_telemetric() # Vendo primeiro se tem telemétrica\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 62020080 -> True\n"
     ]
    }
   ],
   "source": [
    "# Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações telemétricas\n",
    "\n",
    "print(\"Estação {e} -> {p}\".format(\n",
    "                                e=estacao_principal,\n",
    "                                p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "                            )\n",
    ")\n",
    "\n",
    "# A estação principal em questão tem dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 61998080 -> True\n",
      "Estação 01950006 -> False\n",
      "Estação 02050001 -> False\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\"Estação {e} -> {p}\".format(\n",
    "                                        e=e,\n",
    "                                        p=(lista_estacoes['Code'] == e).any()\n",
    "                                    )\n",
    "    )\n",
    "\n",
    "# Estas estações também têm dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações telemétricas\n",
    "\n",
    "estacoes_tele = ['61998080']\n",
    "gerar_dados_tele(\n",
    "    estacao_principal=estacao_principal,\n",
    "    outras_estacoes=estacoes_tele,\n",
    "    nome_arq=\"baixo_rio_grande\",\n",
    "    dt_inicio='2013-01-01',\n",
    "    dt_fim='2023-12-31',\n",
    "    salvar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convencionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cota/Vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758it [00:01, 1701.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type</th>\n",
       "      <th>DrainageArea</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>40023000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>IGAM-MG</td>\n",
       "      <td>-20.3344</td>\n",
       "      <td>-46.4697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VARGEM BONITA</td>\n",
       "      <td>40025000</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>40</td>\n",
       "      <td>VARGEM BONITA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.3272</td>\n",
       "      <td>-46.3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IGUATAMA</td>\n",
       "      <td>40027000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>IGUATAMA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>IGAM-MG</td>\n",
       "      <td>-20.1717</td>\n",
       "      <td>-45.7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAZENDA DA BARCA</td>\n",
       "      <td>40030000</td>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.1000</td>\n",
       "      <td>-46.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAZENDA SAMBURÁ</td>\n",
       "      <td>40032000</td>\n",
       "      <td>1</td>\n",
       "      <td>754</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.1508</td>\n",
       "      <td>-46.3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name      Code Type DrainageArea SubBasin  \\\n",
       "1  SÃO ROQUE DE MINAS  40023000    1         None       40   \n",
       "2       VARGEM BONITA  40025000    1          299       40   \n",
       "3            IGUATAMA  40027000    1         None       40   \n",
       "4    FAZENDA DA BARCA  40030000    1          725       40   \n",
       "5     FAZENDA SAMBURÁ  40032000    1          754       40   \n",
       "\n",
       "                 City         State Responsible  Latitude  Longitude  \n",
       "1  SÃO ROQUE DE MINAS  MINAS GERAIS     IGAM-MG  -20.3344   -46.4697  \n",
       "2       VARGEM BONITA  MINAS GERAIS         ANA  -20.3272   -46.3661  \n",
       "3            IGUATAMA  MINAS GERAIS     IGAM-MG  -20.1717   -45.7261  \n",
       "4  SÃO ROQUE DE MINAS  MINAS GERAIS         ANA  -20.1000   -46.3167  \n",
       "5  SÃO ROQUE DE MINAS  MINAS GERAIS         ANA  -20.1508   -46.3033  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica\n",
    "\n",
    "lista_estacoes = hbr.get_data.ANA.list_flow( # Verificando se tem estações de cota/vazão primeiro\n",
    "    state='MINAS GERAIS',\n",
    "    source='ANA'\n",
    ")\n",
    "\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 62020080 -> False\n"
     ]
    }
   ],
   "source": [
    "# Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações convencionais de cota/vazão\n",
    "\n",
    "print(\n",
    "    \"Estação {e} -> {p}\".format(\n",
    "        e=estacao_principal,\n",
    "        p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "    )\n",
    ")\n",
    "\n",
    "# A estação principal tem dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 61998080 -> False\n",
      "Estação 01950006 -> False\n",
      "Estação 02050001 -> False\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\n",
    "        \"Estação {e} -> {p}\".format(\n",
    "            e=e,\n",
    "            p=(lista_estacoes['Code'] == e).any()\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Estas estações também têm dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# SEM DADOS CONVENCIONAIS DE COTA/VAZAO\n",
    "\n",
    "# estacoes_conv = [\"\"]\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"baixo_rio_grande\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=1, # Cota\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"baixo_rio_grande\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=3, # Vazão\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2434it [00:01, 1812.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AÇUDE DO ESTREITO</td>\n",
       "      <td>01442019</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>DNOCS</td>\n",
       "      <td>-14.8167</td>\n",
       "      <td>-42.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESPIGÃO</td>\n",
       "      <td>01442020</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.9833</td>\n",
       "      <td>-42.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITAMIRIM</td>\n",
       "      <td>01442021</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.7667</td>\n",
       "      <td>-42.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>01442022</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.9333</td>\n",
       "      <td>-42.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>01442025</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>INMET</td>\n",
       "      <td>-14.9333</td>\n",
       "      <td>-42.8167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name      Code Type SubBasin      City         State  \\\n",
       "1  AÇUDE DO ESTREITO  01442019    2       44  ESPINOSA  MINAS GERAIS   \n",
       "2            ESPIGÃO  01442020    2       44  ESPINOSA  MINAS GERAIS   \n",
       "3           ITAMIRIM  01442021    2       44  ESPINOSA  MINAS GERAIS   \n",
       "4           ESPINOSA  01442022    2       44  ESPINOSA  MINAS GERAIS   \n",
       "5           ESPINOSA  01442025    2       44  ESPINOSA  MINAS GERAIS   \n",
       "\n",
       "  Responsible  Latitude  Longitude  \n",
       "1       DNOCS  -14.8167   -42.8000  \n",
       "2      SUDENE  -14.9833   -42.5667  \n",
       "3      SUDENE  -14.7667   -42.8833  \n",
       "4      SUDENE  -14.9333   -42.8167  \n",
       "5       INMET  -14.9333   -42.8167  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_estacoes = hbr.get_data.ANA.list_prec(\n",
    "    state='MINAS GERAIS',\n",
    "    source='ANA'\n",
    ")\n",
    "\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 62020080 -> False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Estação {e} -> {p}\".format(\n",
    "        e=estacao_principal,\n",
    "        p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "    )\n",
    ")\n",
    "\n",
    "# A estação principal NÃO tem dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 61998080 -> False\n",
      "Estação 01950006 -> False\n",
      "Estação 02050001 -> False\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\n",
    "        \"Estação {e} -> {p}\".format(\n",
    "            e=e,\n",
    "            p=(lista_estacoes['Code'] == e).any()\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Estas estações têm dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# SEM DADOS CONVENCIONAIS DE CHUVA\n",
    "\n",
    "# estacoes_conv = [\"\"]\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"baixo_rio_jequitinhonha\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=2, # Chuva\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = [\"baixo_rio_grande_dados_tele.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_ct_62020080</th>\n",
       "      <th>t_cv_62020080</th>\n",
       "      <th>t_vz_62020080</th>\n",
       "      <th>t_ct_61998080</th>\n",
       "      <th>t_cv_61998080</th>\n",
       "      <th>t_vz_61998080</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>32037.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>32592.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>3252.283333</td>\n",
       "      <td>37878.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1874.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>32594.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>3698.487500</td>\n",
       "      <td>37879.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1542.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>32593.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>3620.600000</td>\n",
       "      <td>37873.489583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2566.627586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>32599.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>3672.120833</td>\n",
       "      <td>37863.729167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>32605.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>3665.516667</td>\n",
       "      <td>37861.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3289 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_ct_62020080  t_cv_62020080  t_vz_62020080  t_ct_61998080  \\\n",
       "Data                                                                     \n",
       "2014-12-30   32037.583333              0            NaN            NaN   \n",
       "2014-12-31            NaN              0            NaN            NaN   \n",
       "2015-01-01            NaN              0            NaN            NaN   \n",
       "2015-01-02            NaN              0            NaN            NaN   \n",
       "2015-01-03            NaN              0            NaN            NaN   \n",
       "...                   ...            ...            ...            ...   \n",
       "2023-12-27   32592.583333              0    3252.283333   37878.250000   \n",
       "2023-12-28   32594.750000              0    3698.487500   37879.041667   \n",
       "2023-12-29   32593.833333              0    3620.600000   37873.489583   \n",
       "2023-12-30   32599.750000              0    3672.120833   37863.729167   \n",
       "2023-12-31   32605.833333              0    3665.516667   37861.083333   \n",
       "\n",
       "            t_cv_61998080  t_vz_61998080  \n",
       "Data                                      \n",
       "2014-12-30            NaN            NaN  \n",
       "2014-12-31            NaN            NaN  \n",
       "2015-01-01            NaN            NaN  \n",
       "2015-01-02            NaN            NaN  \n",
       "2015-01-03            NaN            NaN  \n",
       "...                   ...            ...  \n",
       "2023-12-27            0.0    1874.664000  \n",
       "2023-12-28            0.0    1542.200000  \n",
       "2023-12-29            0.0    2566.627586  \n",
       "2023-12-30            0.0    2956.333333  \n",
       "2023-12-31            0.0            NaN  \n",
       "\n",
       "[3289 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vou fazer a carga primeiro dos dados telemétricos, porque é onde tem mais informação de uma única vez.\n",
    "# Depois concateno os outros arquivos. Mas a ordem tanto faz aqui, só estipulei assim porque acho melhor\n",
    "\n",
    "df = pd.read_excel(arquivos[0], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "\n",
    "for a in range(1, len(arquivos)):\n",
    "    df_temp = pd.read_excel(arquivos[a], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "    df = pd.concat([df, df_temp], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_ct_62020080', 't_cv_62020080', 't_vz_62020080', 't_ct_61998080',\n",
       "       't_cv_61998080', 't_vz_61998080'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_cv_62020080</th>\n",
       "      <th>t_vz_62020080</th>\n",
       "      <th>t_cv_61998080</th>\n",
       "      <th>t_vz_61998080</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>3252.283333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1874.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>3698.487500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1542.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0</td>\n",
       "      <td>3620.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2566.627586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>3672.120833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>3665.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3289 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_cv_62020080  t_vz_62020080  t_cv_61998080  t_vz_61998080\n",
       "Data                                                                  \n",
       "2014-12-30              0            NaN            NaN            NaN\n",
       "2014-12-31              0            NaN            NaN            NaN\n",
       "2015-01-01              0            NaN            NaN            NaN\n",
       "2015-01-02              0            NaN            NaN            NaN\n",
       "2015-01-03              0            NaN            NaN            NaN\n",
       "...                   ...            ...            ...            ...\n",
       "2023-12-27              0    3252.283333            0.0    1874.664000\n",
       "2023-12-28              0    3698.487500            0.0    1542.200000\n",
       "2023-12-29              0    3620.600000            0.0    2566.627586\n",
       "2023-12-30              0    3672.120833            0.0    2956.333333\n",
       "2023-12-31              0    3665.516667            0.0            NaN\n",
       "\n",
       "[3289 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vou remover as colunas das cotas\n",
    "\n",
    "df = df.drop(columns=[\"t_ct_62020080\", \"t_ct_61998080\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_cv_62020080', 't_vz_62020080', 't_cv_61998080', 't_vz_61998080'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_cv_62020080 t_cv_61998080 0 169\n",
      "t_vz_62020080 t_vz_61998080 2099 3181\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o merge das colunas de vazão que são correspondentes à mesma estação\n",
    "# Acontece que existem gaps entre os dados, o que é estranho, porque a estação telemétrica tem dados que a convencional não tem e vice-versa.\n",
    "# Vou contar qual coluna tem mais dados e depois executar um 'fillna'\n",
    "\n",
    "colunas_esquerda = ['t_cv_62020080', 't_vz_62020080']\n",
    "colunas_direita = ['t_cv_61998080', 't_vz_61998080']\n",
    "\n",
    "for i, j in zip(colunas_esquerda, colunas_direita):\n",
    "    print(i, j, df[i].isna().sum(), df[j].isna().sum())\n",
    "\n",
    "# A coluna que tiver menos buracos será preenchida com os dados da coluna que tem mais dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preenchendo a coluna que tem menos dados faltantes com a outra correspondente\n",
    "# # Fazer isso para cada coluna, contudo, tem colunas que tem dados faltando demais. Neste caso, darei drop nelas inteiramente.\n",
    "# df['c_vz_56994500'].fillna(df['t_vz_56994500'], inplace=True)\n",
    "# df['t_vz_56990850'].fillna(df['c_vz_56990850'], inplace=True)\n",
    "# df['t_vz_56990005'].fillna(df['c_vz_56990005'], inplace=True)\n",
    "\n",
    "# df['c_vz_56994500'].isna().sum(), df['t_vz_56990850'].isna().sum(), df['t_vz_56990005'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de NaN por coluna\n",
      "t_cv_62020080       0\n",
      "t_vz_62020080    2099\n",
      "t_cv_61998080     169\n",
      "t_vz_61998080    3181\n",
      "dtype: int64\n",
      "Percentual de NaN por coluna\n",
      "t_cv_62020080 0.0\n",
      "t_vz_62020080 63.81878990574643\n",
      "t_cv_61998080 5.138339920948617\n",
      "t_vz_61998080 96.71632715110977\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de valores \"NaN\" em cada coluna\n",
    "\n",
    "print(\"Quantidade de NaN por coluna\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"Percentual de NaN por coluna\")\n",
    "for c in np.asarray(df.columns):\n",
    "    print(c, (df[c].isna().sum()/len(df))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_cv_62020080</th>\n",
       "      <th>t_vz_62020080</th>\n",
       "      <th>t_cv_61998080</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>3252.283333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>3698.487500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0</td>\n",
       "      <td>3620.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>3672.120833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>3665.516667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_cv_62020080  t_vz_62020080  t_cv_61998080\n",
       "Data                                                   \n",
       "2014-12-30              0            NaN            NaN\n",
       "2014-12-31              0            NaN            NaN\n",
       "2015-01-01              0            NaN            NaN\n",
       "2015-01-02              0            NaN            NaN\n",
       "2015-01-03              0            NaN            NaN\n",
       "...                   ...            ...            ...\n",
       "2023-12-27              0    3252.283333            0.0\n",
       "2023-12-28              0    3698.487500            0.0\n",
       "2023-12-29              0    3620.600000            0.0\n",
       "2023-12-30              0    3672.120833            0.0\n",
       "2023-12-31              0    3665.516667            0.0\n",
       "\n",
       "[3289 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta coluna está quase completamente vazia:\n",
    "# t_vz_61998080\n",
    "# Vou remover\n",
    "\n",
    "df = df.drop(columns=[\"t_vz_61998080\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_cv_62020080</th>\n",
       "      <th>t_vz_62020080</th>\n",
       "      <th>t_cv_61998080</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>3252.283333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>3698.487500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0</td>\n",
       "      <td>3620.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>3672.120833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>3665.516667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_cv_62020080  t_vz_62020080  t_cv_61998080\n",
       "Data                                                   \n",
       "2014-12-30              0            NaN            NaN\n",
       "2014-12-31              0            NaN            NaN\n",
       "2015-01-01              0            NaN            NaN\n",
       "2015-01-02              0            NaN            NaN\n",
       "2015-01-03              0            NaN            NaN\n",
       "...                   ...            ...            ...\n",
       "2023-12-27              0    3252.283333            0.0\n",
       "2023-12-28              0    3698.487500            0.0\n",
       "2023-12-29              0    3620.600000            0.0\n",
       "2023-12-30              0    3672.120833            0.0\n",
       "2023-12-31              0    3665.516667            0.0\n",
       "\n",
       "[3289 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deixando os dados contínuos, numa base diária.\n",
    "df = df.resample('D').first()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neste momento, tenho o DataFrame com os dados EXATAMENTE da forma que preciso.\n",
    "# Posso, inclusive, exportar isso para um arquivo de Excel\n",
    "# É o que farei, pois se precisar retornar aos dados originais, será mais fácil que fazer toda engenharia até aqui\n",
    "\n",
    "df.to_excel('./arquivo_final/baixo_rio_grande_final.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertacao_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
