{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  warnings,                   \\\n",
    "        calendar,                   \\\n",
    "        pandas as pd,               \\\n",
    "        numpy as np,                \\\n",
    "        requests as rt,             \\\n",
    "        hydrobr as hbr,             \\\n",
    "        xml.etree.ElementTree as ET\n",
    "from typing import List\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "# Desativar as mensagens de 'warning' que ficam poluindo o output de alguns trechos de código.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(file_name : str,\n",
    "                   separator : str = \"\\t\",\n",
    "                   adjust : bool = True,\n",
    "                   date_column : str = \"ds\"\n",
    "                   ) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_csv(file_name, sep=separator, index_col=date_column, header=0, parse_dates=[date_column])\n",
    "\n",
    "    if adjust:\n",
    "        df = df.resample('D').first() # deixando a série contínua numa base diária\n",
    "\n",
    "    # Deixando ajustado para usar com as libs Nixtla\n",
    "    df['unique_id'] = 1\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def get_telemetrica(codEstacao : str,\n",
    "                    dataInicio : str,\n",
    "                    dataFim : str,\n",
    "                    save : bool = False) -> pd.DataFrame:\n",
    "    # 1. Fazer a requisião ao servidor e pegar a árvore e a raiz dos dados \n",
    "    params = {'codEstacao':codEstacao, 'dataInicio':dataInicio, 'dataFim':dataFim}\n",
    "    server = 'http://telemetriaws1.ana.gov.br/ServiceANA.asmx/DadosHidrometeorologicos'\n",
    "    response = rt.get(server, params)\n",
    "    tree = ET.ElementTree(ET.fromstring(response.content))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # 2. Iteração dentro dos elementos do XML procurando os dados que são disponibilizados para a estação\n",
    "    list_vazao = []\n",
    "    list_data = []\n",
    "    list_cota = []\n",
    "    list_chuva = []\n",
    "\n",
    "    for i in root.iter('DadosHidrometereologicos'):\n",
    "\n",
    "        data = i.find('DataHora').text\n",
    "        try:\n",
    "            vazao = float(i.find('Vazao').text)\n",
    "        except TypeError:\n",
    "            vazao = i.find('Vazao').text\n",
    "\n",
    "        try:\n",
    "            cota = float(i.find('Nivel').text)\n",
    "        except TypeError:\n",
    "            cota = i.find('Nivel').text\n",
    "\n",
    "        try:\n",
    "            chuva = float(i.find('Chuva').text)\n",
    "        except TypeError:\n",
    "            chuva = i.find('Chuva').text\n",
    "\n",
    "        list_vazao.append(vazao)\n",
    "        list_data.append(data)\n",
    "        list_cota.append(cota)\n",
    "        list_chuva.append(chuva)\n",
    "\n",
    "    df = pd.DataFrame([list_data, list_cota, list_chuva, list_vazao]).transpose()\n",
    "    df.columns = ['Data', 'Cota', 'Chuva', 'Vazao']\n",
    "    df = df.sort_values(by='Data')\n",
    "    df = df.set_index('Data')\n",
    "    \n",
    "    if save == True:\n",
    "        df.to_excel(codEstacao+'_dados_tele.xlsx')\n",
    "    \n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def get_convencional(codEstacao : str,\n",
    "                     dataInicio : str,\n",
    "                     dataFim : str,\n",
    "                     tipoDados : int,\n",
    "                     nivelConsistencia : int,\n",
    "                     save : bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Série Histórica estação - HIDRO.\n",
    "        codEstacao : Código Plu ou Flu\n",
    "        dataInicio : <YYYY-mm-dd>\n",
    "        dataFim : Caso não preenchido, trará até o último dado mais recente armazenado\n",
    "        tipoDados : 1-Cotas, 2-Chuvas ou 3-Vazões\n",
    "        nivelConsistencia : 1-Bruto ou 2-Consistido\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Fazer a requisião ao servidor e pegar a árvore e a raiz dos dados \n",
    "    params = {'codEstacao':codEstacao, 'dataInicio':dataInicio, 'dataFim':dataFim,\n",
    "              'tipoDados':tipoDados, 'nivelConsistencia':nivelConsistencia}\n",
    "    \n",
    "    server = 'http://telemetriaws1.ana.gov.br/ServiceANA.asmx/HidroSerieHistorica'\n",
    "    response = rt.get(server, params)\n",
    "    tree = ET.ElementTree(ET.fromstring(response.content))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # 2. Iteração dentro dos elementos do XML procurando os dados que são disponibilizados para a estação\n",
    "    list_data = []\n",
    "    list_consistenciaF = []\n",
    "    list_month_dates = []\n",
    "\n",
    "    for i in root.iter('SerieHistorica'):\n",
    "\n",
    "        consistencia = i.find('NivelConsistencia').text\n",
    "        date = i.find('DataHora').text\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        last_day = calendar.monthrange(date.year, date.month)[1]\n",
    "        month_dates = [date + timedelta(days=i) for i in range(last_day)]\n",
    "        content = []\n",
    "        list_consistencia = []\n",
    "\n",
    "        for day in range(last_day):\n",
    "            if tipoDados == 1:\n",
    "                value = f'Cota{day+1:02d}'\n",
    "            if tipoDados == 2:\n",
    "                value = f'Chuva{day+1:02d}'\n",
    "            if tipoDados == 3:\n",
    "                value = f'Vazao{day+1:02d}'\n",
    "            \n",
    "            try:\n",
    "                content.append(float(i.find(value).text))\n",
    "                list_consistencia.append(int(consistencia))\n",
    "            except TypeError:\n",
    "                content.append(i.find(value).text)\n",
    "                list_consistencia.append(int(consistencia))\n",
    "            except AttributeError:\n",
    "                content.append(None)\n",
    "                list_consistencia.append(int(consistencia))\n",
    "        \n",
    "        list_data += content\n",
    "        list_consistenciaF += list_consistencia\n",
    "        list_month_dates += month_dates\n",
    "    df = pd.DataFrame([list_month_dates, list_consistenciaF, list_data]).transpose()\n",
    "\n",
    "    if tipoDados == 1:\n",
    "        df.columns = ['Data','Consistencia','Cota']\n",
    "    elif tipoDados == 2:\n",
    "        df.columns = ['Data','Consistencia','Chuva']\n",
    "    else: # Vazão\n",
    "        df.columns = ['Data','Consistencia','Vazao']\n",
    "    \n",
    "    df = df.sort_values(by='Data')\n",
    "    df = df.set_index('Data')\n",
    "\n",
    "    if save == True:\n",
    "        df.to_excel(codEstacao + '_dados_conv.xlsx')\n",
    "    \n",
    "    return df\n",
    "# ============================================================================================ #\n",
    "def gerar_dados_tele(estacao_principal : str,\n",
    "                    outras_estacoes : List[str],\n",
    "                    nome_arq : str,\n",
    "                    dt_inicio : str,\n",
    "                    dt_fim : str,\n",
    "                    salvar : bool = False) -> None:\n",
    "    \"\"\"\n",
    "            Este método vai pegar o código da 'estacao_principal' (que o usuário já sabe previamente que é uma telemétrica), baixar os dados da estação\n",
    "        e concatenar (outer join) com os dados das outras estações telemétricas. Neste método já será realizada a conversão dos dados de 'object' para\n",
    "        os tipos de acordo, ou seja, 'float' para os campos numéricos e 'datetime' para os campos de datahora.\n",
    "            Como o desejo do trabalho é lidar com dados diários, já aproveita pra fazer a agregação dos dados desta maneira também.\n",
    "            Após tudo isso, salva num arquivo xlsx para usos posteriores.\n",
    "\n",
    "        Parâmetros:\n",
    "            estacao_principal : str,\n",
    "            outras_estacoes : List[str],\n",
    "            nome_arq : str,\n",
    "            dt_inicio : str = 'YYYY-mm-dd',\n",
    "            dt_fim : str = 'YYYY-mm-dd',\n",
    "            salvar : bool = True|False\n",
    "    \"\"\"\n",
    "\n",
    "    df_result = get_telemetrica(codEstacao=estacao_principal, dataInicio=dt_inicio, dataFim=dt_fim)\n",
    "\n",
    "    df_result.index = pd.to_datetime(df_result.index)\n",
    "    df_result.Cota = pd.to_numeric(df_result.Cota, errors='coerce')\n",
    "    df_result.Chuva = pd.to_numeric(df_result.Chuva, errors='coerce')\n",
    "    df_result.Vazao = pd.to_numeric(df_result.Vazao, errors='coerce')\n",
    "\n",
    "    df_result = df_result.resample('D').agg({'Cota': 'mean', 'Chuva': 'sum', 'Vazao': 'mean'})\n",
    "\n",
    "    df_result.columns = ['t_ct_'+str(estacao_principal), 't_cv_'+str(estacao_principal), 't_vz_'+str(estacao_principal)]\n",
    "\n",
    "    # Agora que já tenho os dados da estação que considero principal na análise (target)\n",
    "    #   vou agregar com os dados das demais estações\n",
    "\n",
    "    if outras_estacoes is not None:\n",
    "        for e in outras_estacoes:\n",
    "            df_temp = get_telemetrica(codEstacao=e, dataInicio=dt_inicio, dataFim=dt_fim)\n",
    "\n",
    "            # Convertendo os dados\n",
    "            df_temp.index = pd.to_datetime(df_temp.index)\n",
    "            df_temp.Cota = pd.to_numeric(df_temp.Cota, errors='coerce')\n",
    "            df_temp.Chuva = pd.to_numeric(df_temp.Chuva, errors='coerce')\n",
    "            df_temp.Vazao = pd.to_numeric(df_temp.Vazao, errors='coerce')\n",
    "\n",
    "            # Para as telemétricas já agrego aqui mesmo\n",
    "            df_temp = df_temp.resample('D').agg({'Cota': 'mean', 'Chuva': 'sum', 'Vazao': 'mean'})\n",
    "\n",
    "            # Ajeito os nomes das colunas pra conter de qual estacao os dado veio\n",
    "            df_temp.columns = ['t_ct_'+e, 't_cv_'+e, 't_vz_'+e]\n",
    "\n",
    "            df_result = pd.concat([df_result, df_temp], axis=1)\n",
    "\n",
    "    if salvar:\n",
    "        df_result.to_excel(nome_arq+'_dados_tele.xlsx')\n",
    "# ============================================================================================ #\n",
    "def gerar_dados_conv(estacao_principal : str,\n",
    "                    outras_estacoes : List[str],\n",
    "                    nome_arq : str,\n",
    "                    dt_inicio : str,\n",
    "                    dt_fim : str,\n",
    "                    tp_dados : int,\n",
    "                    nvl_consistencia : str,\n",
    "                    drop_consistencia : bool = True, # Remover a coluna \"NivelConsistência\". Ela será irrelevante, até segunda ordem.\n",
    "                    salvar : bool = False) -> None:\n",
    "    \"\"\"\n",
    "            Este método vai pegar o código da 'estacao_principal' (que o usuário já sabe previamente que é uma convencional), baixar os dados da estação\n",
    "        e concatenar (outer join) com os dados das outras estações convencionais. Neste método já será realizada a conversão dos dados de 'object' para\n",
    "        os tipos de acordo, ou seja, 'float' para os campos numéricos e 'datetime' para os campos de datahora.\n",
    "            Como o desejo do trabalho é lidar com dados diários, já aproveita pra fazer a agregação dos dados desta maneira também.\n",
    "            Após tudo isso, salva num arquivo xlsx para usos posteriores.\n",
    "\n",
    "        Parâmetros:\n",
    "            estacao_principal : str,\n",
    "            outras_estacoes : List[str],\n",
    "            nome_arq : str,\n",
    "            dt_inicio : str = 'YYYY-mm-dd',\n",
    "            dt_fim : str = 'YYYY-mm-dd',\n",
    "            tp_dados : int (1-cota | 2-chuva | 3-vazao),\n",
    "            nvl_consistencia : int (1-bruto | 2-consistido),\n",
    "            drop_consistencia : bool = True, (Remover a coluna \"NivelConsistência\". Ela será irrelevante, até segunda ordem)\n",
    "            salvar : bool = False\n",
    "    \"\"\"\n",
    "\n",
    "    df_result = get_convencional(codEstacao=estacao_principal, dataInicio=dt_inicio, dataFim=dt_fim, tipoDados=tp_dados, nivelConsistencia=nvl_consistencia)\n",
    "\n",
    "    df_result.index = pd.to_datetime(df_result.index)\n",
    "\n",
    "    if drop_consistencia:\n",
    "        df_result.drop(columns=['Consistencia'], inplace=True)\n",
    "\n",
    "    if tp_dados == 1:\n",
    "        df_result.Cota = pd.to_numeric(df_result.Cota, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Cota': 'mean'})\n",
    "        df_result.columns = ['c_ct_'+str(estacao_principal)]\n",
    "    elif tp_dados == 2:\n",
    "        df_result.Chuva = pd.to_numeric(df_result.Chuva, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Chuva': 'sum'})\n",
    "        df_result.columns = ['c_cv_'+str(estacao_principal)]\n",
    "    else: # Vazão\n",
    "        df_result.Vazao = pd.to_numeric(df_result.Vazao, errors='coerce')\n",
    "        df_result = df_result.resample('D').agg({'Vazao': 'mean'})\n",
    "        df_result.columns = ['c_vz_'+str(estacao_principal)]\n",
    "\n",
    "    # Agora que já tenho os dados da estação que considero principal na análise (target)\n",
    "    #   vou agregar com os dados das demais estações\n",
    "\n",
    "    for e in outras_estacoes:\n",
    "        df_temp = get_convencional(codEstacao=e, dataInicio=dt_inicio, dataFim=dt_fim, tipoDados=tp_dados, nivelConsistencia=nvl_consistencia)\n",
    "\n",
    "        # Convertendo os dados\n",
    "        df_temp.index = pd.to_datetime(df_temp.index)\n",
    "\n",
    "        if drop_consistencia:\n",
    "            df_temp.drop(columns=['Consistencia'], inplace=True)\n",
    "\n",
    "        if tp_dados == 1:\n",
    "            df_temp.Cota = pd.to_numeric(df_temp.Cota, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Cota': 'mean'})\n",
    "            df_temp.columns = ['c_ct_'+str(e)]\n",
    "        elif tp_dados == 2:\n",
    "            df_temp.Chuva = pd.to_numeric(df_temp.Chuva, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Chuva': 'sum'})\n",
    "            df_temp.columns = ['c_cv_'+str(e)]\n",
    "        else:\n",
    "            df_temp.Vazao = pd.to_numeric(df_temp.Vazao, errors='coerce')\n",
    "            df_temp = df_temp.resample('D').agg({'Vazao': 'mean'})\n",
    "            df_temp.columns = ['c_vz_'+str(e)]\n",
    "\n",
    "        df_result = pd.concat([df_result, df_temp], axis=1)\n",
    "\n",
    "    if salvar:\n",
    "        if tp_dados == 1:\n",
    "            df_result.to_excel(nome_arq + '_dados_cota_conv.xlsx')\n",
    "        elif tp_dados == 2:\n",
    "            df_result.to_excel(nome_arq + '_dados_chuva_conv.xlsx')\n",
    "        else:\n",
    "            df_result.to_excel(nome_arq + '_dados_vazao_conv.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Médio Rio Jequitinhonha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baixando os dados das estações que serão utilizadas no trabalho\n",
    "# # As estações foram selecionadas a partir do sistema Data Rhama\n",
    "# # Aqui eu baixo os dados e salvo localmente\n",
    "# # >>>>>>>>>>>>> SÓ PRECISA FAZER ISSO UMA VEZ, POR ISSO O CÓDIGO FICA COMENTADO DEPOIS DE RODAR!!!! <<<<<<<<<<<<<\n",
    "\n",
    "# estacao_principal = '56920000'\n",
    "# outras_estacoes = ['01941018', '56846900', '56846890', '01841011', '56850000', '56846200', '56895000', '01841020', '01841029']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemétricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# # O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica, como é o caso aqui\n",
    "\n",
    "# lista_estacoes = hbr.get_data.ANA.list_telemetric() # Vendo primeiro se tem telemétrica\n",
    "# lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações telemétricas\n",
    "\n",
    "# print(\n",
    "#     \"Estação {e} -> {p}\".format(\n",
    "#         e=estacao_principal,\n",
    "#         p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # A estação principal em questão tem dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verificando as outras estações\n",
    "\n",
    "# for e in outras_estacoes:\n",
    "#     print(\n",
    "#         \"Estação {e} -> {p}\".format(\n",
    "#             e=e,\n",
    "#             p=(lista_estacoes['Code'] == e).any()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Estas estações também têm dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gerando um arquivo Excel com os dados das estações telemétricas\n",
    "\n",
    "# estacoes_tele = [\"56850000\", \"56846200\", \"56895000\", \"01841029\"]\n",
    "# gerar_dados_tele(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_tele,\n",
    "#     nome_arq=\"medio_rio_doce\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convencionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cota/Vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# # O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica, como é o caso aqui\n",
    "\n",
    "# lista_estacoes = hbr.get_data.ANA.list_flow( # Verificando se tem estações de cota/vazão primeiro\n",
    "#     state='MINAS GERAIS',\n",
    "#     source='ANA'\n",
    "# )\n",
    "\n",
    "# lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações convencionais de cota/vazão\n",
    "\n",
    "# print(\n",
    "#     \"Estação {e} -> {p}\".format(\n",
    "#         e=estacao_principal,\n",
    "#         p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # A estação principal tem dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verificando as outras estações\n",
    "\n",
    "# for e in outras_estacoes:\n",
    "#     print(\n",
    "#         \"Estação {e} -> {p}\".format(\n",
    "#             e=e,\n",
    "#             p=(lista_estacoes['Code'] == e).any()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Estas estações também têm dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# estacoes_conv = [\"56846900\", \"56846890\", \"56850000\", \"56846200\", \"56895000\"]\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"medio_rio_doce\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=1, # Cota\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"medio_rio_doce\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=3, # Vazão\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_estacoes = hbr.get_data.ANA.list_prec(\n",
    "#     state='MINAS GERAIS',\n",
    "#     source='ANA'\n",
    "# )\n",
    "\n",
    "# lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Estação {e} -> {p}\".format(\n",
    "#         e=estacao_principal,\n",
    "#         p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # A estação principal NÃO tem dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verificando as outras estações\n",
    "\n",
    "# for e in outras_estacoes:\n",
    "#     print(\n",
    "#         \"Estação {e} -> {p}\".format(\n",
    "#             e=e,\n",
    "#             p=(lista_estacoes['Code'] == e).any()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Estas estações também NÃO têm dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "# estacoes_conv = [\"01941018\", \"01841011\", \"01841020\", \"01841029\"]\n",
    "# gerar_dados_conv(\n",
    "#     estacao_principal=estacao_principal,\n",
    "#     outras_estacoes=estacoes_conv,\n",
    "#     nome_arq=\"medio_rio_doce\",\n",
    "#     dt_inicio='2013-01-01',\n",
    "#     dt_fim='2023-12-31',\n",
    "#     tp_dados=2, # Chuva\n",
    "#     nvl_consistencia='2', # dados consistidos\n",
    "#     salvar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Como estou em dúvida com o arquivo de cotas, deixei apenas estes dois arquivos pra trabalhar.\n",
    "\n",
    "# arquivos = ['medio_rio_doce_dados_tele.xlsx', 'medio_rio_doce_dados_vazao_conv.xlsx', 'medio_rio_doce_dados_chuva_conv.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vou fazer a carga primeiro dos dados telemétricos, porque é onde tem mais informação de uma única vez.\n",
    "# # Depois concateno os outros arquivos. Mas a ordem tanto faz aqui, só estipulei assim porque acho melhor\n",
    "\n",
    "# df = pd.read_excel(arquivos[0], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "\n",
    "# for a in range(1, len(arquivos)):\n",
    "#     df_temp = pd.read_excel(arquivos[a], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "#     df = pd.concat([df, df_temp], axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vou remover as colunas das cotas\n",
    "\n",
    "# df = df.drop(columns=['t_ct_56920000', 't_ct_56850000', 't_ct_56846200', 't_ct_56895000', 't_ct_01841029'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fazendo o merge das colunas de vazão que são correspondentes à mesma estação\n",
    "# # Acontece que existem gaps entre os dados, o que é estranho, porque a estação telemétrica tem dados que a convencional não tem e vice-versa.\n",
    "# # Vou contar qual coluna tem mais dados e depois executar um 'fillna'\n",
    "\n",
    "# colunas_esquerda = ['t_vz_56920000', 't_vz_56850000', 't_vz_56846200', 't_vz_56895000']\n",
    "# colunas_direita = ['c_vz_56920000', 'c_vz_56850000', 'c_vz_56846200', 'c_vz_56895000']\n",
    "\n",
    "# for i, j in zip(colunas_esquerda, colunas_direita):\n",
    "#     print(i, j, df[i].isna().sum(), df[j].isna().sum())\n",
    "\n",
    "# # A coluna que tiver menos buracos será preenchida com os dados da coluna que tem mais dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preenchendo a coluna que tem menos dados faltantes com a outra correspondente\n",
    "# # Fazer isso para cada coluna, contudo, tem colunas que tem dados faltando demais. Neste caso, darei drop nelas inteiramente.\n",
    "# df['c_vz_56920000'].fillna(df['t_vz_56920000'], inplace=True)\n",
    "# df['c_vz_56850000'].fillna(df['t_vz_56850000'], inplace=True)\n",
    "# df['t_vz_56846200'].fillna(df['c_vz_56846200'], inplace=True)\n",
    "# df['t_vz_56895000'].fillna(df['c_vz_56895000'], inplace=True)\n",
    "\n",
    "# df['c_vz_56920000'].isna().sum(), df['c_vz_56850000'].isna().sum(), df['t_vz_56846200'].isna().sum(), df['t_vz_56895000'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uma vez que as colunas estejam ajustadas, eu dropo as que não vou precisar mais\n",
    "# df = df.drop(columns=['t_vz_56920000', 't_vz_56850000', 'c_vz_56846200', 'c_vz_56895000', 't_vz_56895000'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verificando a quantidade de valores \"NaN\" em cada coluna\n",
    "\n",
    "# print(\"Quantidade de NaN por coluna\")\n",
    "# print(df.isna().sum())\n",
    "\n",
    "# print(\"Percentual de NaN por coluna\")\n",
    "# for c in np.asarray(df.columns):\n",
    "#     print(c, (df[c].isna().sum()/len(df))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removendo as colunas porque elas têm MUITOS  dados faltantes.\n",
    "\n",
    "# df = df.drop(columns=['t_cv_01841029', 't_vz_01841029', 'c_vz_56846900'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deixando os dados contínuos, numa base diária.\n",
    "# df = df.resample('D').first()\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando os dados finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Neste momento, tenho o DataFrame com os dados EXATAMENTE da forma que preciso.\n",
    "# # Posso, inclusive, exportar isso para um arquivo de Excel\n",
    "# # É o que farei, pois se precisar retornar aos dados originais, será mais fácil que fazer toda engenharia até aqui\n",
    "\n",
    "# df.to_excel('./arquivos_finais/medio_rio_doce_final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixo Rio Jequitinhonha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando os dados das estações que serão utilizadas no trabalho\n",
    "# As estações foram selecionadas a partir do sistema Data Rhama\n",
    "# Aqui eu baixo os dados e salvo localmente\n",
    "# >>>>>>>>>>>>> SÓ PRECISA FAZER ISSO UMA VEZ, POR ISSO O CÓDIGO FICA COMENTADO DEPOIS DE RODAR!!!! <<<<<<<<<<<<<\n",
    "\n",
    "estacao_principal = '54790000'\n",
    "outras_estacoes = ['54780000', '01640007', '01640000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemétricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4819it [00:04, 1125.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City-State</th>\n",
       "      <th>Origem</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIO PRETO DA EVA</td>\n",
       "      <td>00259004</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>15</td>\n",
       "      <td>RIO PRETO DA EVA-AM</td>\n",
       "      <td>Açudes Semiárido</td>\n",
       "      <td>00001 - ANA - Agência Nacional de Águas</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.7003</td>\n",
       "      <td>-59.6997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UHE BELO MONTE BR230</td>\n",
       "      <td>00351004</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>VITÓRIA DO XINGU-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>33.00</td>\n",
       "      <td>-3.1267</td>\n",
       "      <td>-51.7906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UHE BELO MONTE SÍTIO PIMENTAL</td>\n",
       "      <td>00351005</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>VITÓRIA DO XINGU-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>110.00</td>\n",
       "      <td>-3.3758</td>\n",
       "      <td>-51.9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UHE BELO MONTE VISTA ALEGRE</td>\n",
       "      <td>00352009</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>ALTAMIRA-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>125.00</td>\n",
       "      <td>-3.1186</td>\n",
       "      <td>-52.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UHE BELO MONTE SÃO FRANCISCO</td>\n",
       "      <td>00352010</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>18</td>\n",
       "      <td>ALTAMIRA-PA</td>\n",
       "      <td>Setor Elétrico</td>\n",
       "      <td>00594 - NORTE ENERGIA - Norte Energia S.A</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-3.2533</td>\n",
       "      <td>-52.3489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name      Code Status SubBasin  \\\n",
       "1               RIO PRETO DA EVA  00259004  Ativo       15   \n",
       "2           UHE BELO MONTE BR230  00351004  Ativo       18   \n",
       "3  UHE BELO MONTE SÍTIO PIMENTAL  00351005  Ativo       18   \n",
       "4    UHE BELO MONTE VISTA ALEGRE  00352009  Ativo       18   \n",
       "5   UHE BELO MONTE SÃO FRANCISCO  00352010  Ativo       18   \n",
       "\n",
       "            City-State            Origem  \\\n",
       "1  RIO PRETO DA EVA-AM  Açudes Semiárido   \n",
       "2  VITÓRIA DO XINGU-PA    Setor Elétrico   \n",
       "3  VITÓRIA DO XINGU-PA    Setor Elétrico   \n",
       "4          ALTAMIRA-PA    Setor Elétrico   \n",
       "5          ALTAMIRA-PA    Setor Elétrico   \n",
       "\n",
       "                                 Responsible Elevation  Latitude  Longitude  \n",
       "1   00001 - ANA - Agência Nacional de Águas       0.00   -2.7003   -59.6997  \n",
       "2  00594 - NORTE ENERGIA - Norte Energia S.A     33.00   -3.1267   -51.7906  \n",
       "3  00594 - NORTE ENERGIA - Norte Energia S.A    110.00   -3.3758   -51.9403  \n",
       "4  00594 - NORTE ENERGIA - Norte Energia S.A    125.00   -3.1186   -52.2525  \n",
       "5  00594 - NORTE ENERGIA - Norte Energia S.A    124.00   -3.2533   -52.3489  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica, como é o caso aqui\n",
    "\n",
    "lista_estacoes = hbr.get_data.ANA.list_telemetric() # Vendo primeiro se tem telemétrica\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54790000 -> True\n"
     ]
    }
   ],
   "source": [
    "# Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações telemétricas\n",
    "\n",
    "print(\"Estação {e} -> {p}\".format(\n",
    "                                e=estacao_principal,\n",
    "                                p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "                            )\n",
    ")\n",
    "\n",
    "# A estação principal em questão tem dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54780000 -> False\n",
      "Estação 01640007 -> False\n",
      "Estação 01640000 -> False\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\"Estação {e} -> {p}\".format(\n",
    "                                        e=e,\n",
    "                                        p=(lista_estacoes['Code'] == e).any()\n",
    "                                    )\n",
    "    )\n",
    "\n",
    "# Estas estações também têm dados telemétricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações telemétricas\n",
    "\n",
    "gerar_dados_tele(\n",
    "    estacao_principal=estacao_principal,\n",
    "    outras_estacoes=None,\n",
    "    nome_arq=\"baixo_rio_jequitinhonha\",\n",
    "    dt_inicio='2013-01-01',\n",
    "    dt_fim='2023-12-31',\n",
    "    salvar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convencionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cota/Vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758it [00:01, 1651.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type</th>\n",
       "      <th>DrainageArea</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>40023000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>IGAM-MG</td>\n",
       "      <td>-20.3344</td>\n",
       "      <td>-46.4697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VARGEM BONITA</td>\n",
       "      <td>40025000</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>40</td>\n",
       "      <td>VARGEM BONITA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.3272</td>\n",
       "      <td>-46.3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IGUATAMA</td>\n",
       "      <td>40027000</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>IGUATAMA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>IGAM-MG</td>\n",
       "      <td>-20.1717</td>\n",
       "      <td>-45.7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAZENDA DA BARCA</td>\n",
       "      <td>40030000</td>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.1000</td>\n",
       "      <td>-46.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAZENDA SAMBURÁ</td>\n",
       "      <td>40032000</td>\n",
       "      <td>1</td>\n",
       "      <td>754</td>\n",
       "      <td>40</td>\n",
       "      <td>SÃO ROQUE DE MINAS</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>ANA</td>\n",
       "      <td>-20.1508</td>\n",
       "      <td>-46.3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name      Code Type DrainageArea SubBasin  \\\n",
       "1  SÃO ROQUE DE MINAS  40023000    1         None       40   \n",
       "2       VARGEM BONITA  40025000    1          299       40   \n",
       "3            IGUATAMA  40027000    1         None       40   \n",
       "4    FAZENDA DA BARCA  40030000    1          725       40   \n",
       "5     FAZENDA SAMBURÁ  40032000    1          754       40   \n",
       "\n",
       "                 City         State Responsible  Latitude  Longitude  \n",
       "1  SÃO ROQUE DE MINAS  MINAS GERAIS     IGAM-MG  -20.3344   -46.4697  \n",
       "2       VARGEM BONITA  MINAS GERAIS         ANA  -20.3272   -46.3661  \n",
       "3            IGUATAMA  MINAS GERAIS     IGAM-MG  -20.1717   -45.7261  \n",
       "4  SÃO ROQUE DE MINAS  MINAS GERAIS         ANA  -20.1000   -46.3167  \n",
       "5  SÃO ROQUE DE MINAS  MINAS GERAIS         ANA  -20.1508   -46.3033  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a lib HydroBR eu desejo saber se as estações em questão são do tipo convencional ou telemétrica\n",
    "# O código não exclui o fato, eventual, de uma dada estação ser convencional E telemétrica\n",
    "\n",
    "lista_estacoes = hbr.get_data.ANA.list_flow( # Verificando se tem estações de cota/vazão primeiro\n",
    "    state='MINAS GERAIS',\n",
    "    source='ANA'\n",
    ")\n",
    "\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54790000 -> True\n"
     ]
    }
   ],
   "source": [
    "# Averiguando se as estações que tenho em mãos estão presentes neste conjunto de estações convencionais de cota/vazão\n",
    "\n",
    "print(\n",
    "    \"Estação {e} -> {p}\".format(\n",
    "        e=estacao_principal,\n",
    "        p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "    )\n",
    ")\n",
    "\n",
    "# A estação principal tem dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54780000 -> True\n",
      "Estação 01640007 -> False\n",
      "Estação 01640000 -> False\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\n",
    "        \"Estação {e} -> {p}\".format(\n",
    "            e=e,\n",
    "            p=(lista_estacoes['Code'] == e).any()\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Estas estações também têm dados convencionais de cota/vazão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "estacoes_conv = [\"54780000\"]\n",
    "gerar_dados_conv(\n",
    "    estacao_principal=estacao_principal,\n",
    "    outras_estacoes=estacoes_conv,\n",
    "    nome_arq=\"baixo_rio_jequitinhonha\",\n",
    "    dt_inicio='2013-01-01',\n",
    "    dt_fim='2023-12-31',\n",
    "    tp_dados=1, # Cota\n",
    "    nvl_consistencia='2', # dados consistidos\n",
    "    salvar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "gerar_dados_conv(\n",
    "    estacao_principal=estacao_principal,\n",
    "    outras_estacoes=estacoes_conv,\n",
    "    nome_arq=\"baixo_rio_jequitinhonha\",\n",
    "    dt_inicio='2013-01-01',\n",
    "    dt_fim='2023-12-31',\n",
    "    tp_dados=3, # Vazão\n",
    "    nvl_consistencia='2', # dados consistidos\n",
    "    salvar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2434it [00:01, 1791.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type</th>\n",
       "      <th>SubBasin</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AÇUDE DO ESTREITO</td>\n",
       "      <td>01442019</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>DNOCS</td>\n",
       "      <td>-14.8167</td>\n",
       "      <td>-42.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESPIGÃO</td>\n",
       "      <td>01442020</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.9833</td>\n",
       "      <td>-42.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITAMIRIM</td>\n",
       "      <td>01442021</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.7667</td>\n",
       "      <td>-42.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>01442022</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>SUDENE</td>\n",
       "      <td>-14.9333</td>\n",
       "      <td>-42.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>01442025</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>ESPINOSA</td>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>INMET</td>\n",
       "      <td>-14.9333</td>\n",
       "      <td>-42.8167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name      Code Type SubBasin      City         State  \\\n",
       "1  AÇUDE DO ESTREITO  01442019    2       44  ESPINOSA  MINAS GERAIS   \n",
       "2            ESPIGÃO  01442020    2       44  ESPINOSA  MINAS GERAIS   \n",
       "3           ITAMIRIM  01442021    2       44  ESPINOSA  MINAS GERAIS   \n",
       "4           ESPINOSA  01442022    2       44  ESPINOSA  MINAS GERAIS   \n",
       "5           ESPINOSA  01442025    2       44  ESPINOSA  MINAS GERAIS   \n",
       "\n",
       "  Responsible  Latitude  Longitude  \n",
       "1       DNOCS  -14.8167   -42.8000  \n",
       "2      SUDENE  -14.9833   -42.5667  \n",
       "3      SUDENE  -14.7667   -42.8833  \n",
       "4      SUDENE  -14.9333   -42.8167  \n",
       "5       INMET  -14.9333   -42.8167  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_estacoes = hbr.get_data.ANA.list_prec(\n",
    "    state='MINAS GERAIS',\n",
    "    source='ANA'\n",
    ")\n",
    "\n",
    "lista_estacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54790000 -> False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Estação {e} -> {p}\".format(\n",
    "        e=estacao_principal,\n",
    "        p=(lista_estacoes['Code'] == estacao_principal).any()\n",
    "    )\n",
    ")\n",
    "\n",
    "# A estação principal NÃO tem dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação 54780000 -> False\n",
      "Estação 01640007 -> True\n",
      "Estação 01640000 -> True\n"
     ]
    }
   ],
   "source": [
    "# Verificando as outras estações\n",
    "\n",
    "for e in outras_estacoes:\n",
    "    print(\n",
    "        \"Estação {e} -> {p}\".format(\n",
    "            e=e,\n",
    "            p=(lista_estacoes['Code'] == e).any()\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Estas estações têm dados convencionais de chuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo Excel com os dados das estações convencionais\n",
    "\n",
    "estacoes_conv = [\"01640007\", \"01640000\"]\n",
    "gerar_dados_conv(\n",
    "    estacao_principal=estacao_principal,\n",
    "    outras_estacoes=estacoes_conv,\n",
    "    nome_arq=\"baixo_rio_jequitinhonha\",\n",
    "    dt_inicio='2013-01-01',\n",
    "    dt_fim='2023-12-31',\n",
    "    tp_dados=2, # Chuva\n",
    "    nvl_consistencia='2', # dados consistidos\n",
    "    salvar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = [\n",
    "    \"baixo_rio_jequitinhonha_dados_chuva_conv.xlsx\",\n",
    "    \"baixo_rio_jequitinhonha_dados_tele.xlsx\",\n",
    "    \"baixo_rio_jequitinhonha_dados_vazao_conv.xlsx\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_cv_54790000</th>\n",
       "      <th>c_cv_01640007</th>\n",
       "      <th>c_cv_01640000</th>\n",
       "      <th>t_ct_54790000</th>\n",
       "      <th>t_cv_54790000</th>\n",
       "      <th>t_vz_54790000</th>\n",
       "      <th>c_vz_54790000</th>\n",
       "      <th>c_vz_54780000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436.354167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.450000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>422.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.420833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>404.208333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>117.235417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390.979167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.239583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>398.229167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.920833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.8542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_cv_54790000  c_cv_01640007  c_cv_01640000  t_ct_54790000  \\\n",
       "Data                                                                     \n",
       "2013-01-01            NaN            NaN            0.6            NaN   \n",
       "2013-01-02            NaN            NaN            0.0            NaN   \n",
       "2013-01-03            NaN            NaN           13.2            NaN   \n",
       "2013-01-04            NaN            NaN            0.0            NaN   \n",
       "2013-01-05            NaN            NaN            0.0            NaN   \n",
       "...                   ...            ...            ...            ...   \n",
       "2023-12-27            NaN            NaN            0.0     436.354167   \n",
       "2023-12-28            NaN            NaN            0.0     422.375000   \n",
       "2023-12-29            NaN            NaN            0.0     404.208333   \n",
       "2023-12-30            NaN            NaN            0.0     390.979167   \n",
       "2023-12-31            NaN            NaN            7.5     398.229167   \n",
       "\n",
       "            t_cv_54790000  t_vz_54790000  c_vz_54790000  c_vz_54780000  \n",
       "Data                                                                    \n",
       "2013-01-01            NaN            NaN            NaN       187.7730  \n",
       "2013-01-02            NaN            NaN            NaN       105.3130  \n",
       "2013-01-03            NaN            NaN            NaN       101.8800  \n",
       "2013-01-04            NaN            NaN            NaN        98.5206  \n",
       "2013-01-05            NaN            NaN            NaN        98.5206  \n",
       "...                   ...            ...            ...            ...  \n",
       "2023-12-27            0.0     211.450000            NaN       442.6400  \n",
       "2023-12-28            0.0     167.420833            NaN       131.6670  \n",
       "2023-12-29            0.6     117.235417            NaN       121.8540  \n",
       "2023-12-30            0.0      94.239583            NaN        93.7937  \n",
       "2023-12-31            0.0     103.920833            NaN        97.8542  \n",
       "\n",
       "[4017 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vou fazer a carga primeiro dos dados telemétricos, porque é onde tem mais informação de uma única vez.\n",
    "# Depois concateno os outros arquivos. Mas a ordem tanto faz aqui, só estipulei assim porque acho melhor\n",
    "\n",
    "df = pd.read_excel(arquivos[0], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "\n",
    "for a in range(1, len(arquivos)):\n",
    "    df_temp = pd.read_excel(arquivos[a], sheet_name=0, index_col=0, header=0, parse_dates=['Data'])\n",
    "    df = pd.concat([df, df_temp], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_cv_54790000', 'c_cv_01640007', 'c_cv_01640000', 't_ct_54790000',\n",
       "       't_cv_54790000', 't_vz_54790000', 'c_vz_54790000', 'c_vz_54780000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_cv_54790000</th>\n",
       "      <th>c_cv_01640007</th>\n",
       "      <th>c_cv_01640000</th>\n",
       "      <th>t_cv_54790000</th>\n",
       "      <th>t_vz_54790000</th>\n",
       "      <th>c_vz_54790000</th>\n",
       "      <th>c_vz_54780000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.450000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.420833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>117.235417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.239583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.920833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.8542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_cv_54790000  c_cv_01640007  c_cv_01640000  t_cv_54790000  \\\n",
       "Data                                                                     \n",
       "2013-01-01            NaN            NaN            0.6            NaN   \n",
       "2013-01-02            NaN            NaN            0.0            NaN   \n",
       "2013-01-03            NaN            NaN           13.2            NaN   \n",
       "2013-01-04            NaN            NaN            0.0            NaN   \n",
       "2013-01-05            NaN            NaN            0.0            NaN   \n",
       "...                   ...            ...            ...            ...   \n",
       "2023-12-27            NaN            NaN            0.0            0.0   \n",
       "2023-12-28            NaN            NaN            0.0            0.0   \n",
       "2023-12-29            NaN            NaN            0.0            0.6   \n",
       "2023-12-30            NaN            NaN            0.0            0.0   \n",
       "2023-12-31            NaN            NaN            7.5            0.0   \n",
       "\n",
       "            t_vz_54790000  c_vz_54790000  c_vz_54780000  \n",
       "Data                                                     \n",
       "2013-01-01            NaN            NaN       187.7730  \n",
       "2013-01-02            NaN            NaN       105.3130  \n",
       "2013-01-03            NaN            NaN       101.8800  \n",
       "2013-01-04            NaN            NaN        98.5206  \n",
       "2013-01-05            NaN            NaN        98.5206  \n",
       "...                   ...            ...            ...  \n",
       "2023-12-27     211.450000            NaN       442.6400  \n",
       "2023-12-28     167.420833            NaN       131.6670  \n",
       "2023-12-29     117.235417            NaN       121.8540  \n",
       "2023-12-30      94.239583            NaN        93.7937  \n",
       "2023-12-31     103.920833            NaN        97.8542  \n",
       "\n",
       "[4017 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vou remover as colunas das cotas\n",
    "\n",
    "df = df.drop(columns=[\"t_ct_54790000\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_cv_54790000', 'c_cv_01640007', 'c_cv_01640000', 't_cv_54790000',\n",
       "       't_vz_54790000', 'c_vz_54790000', 'c_vz_54780000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_cv_54790000 t_cv_54790000 4017 273\n",
      "c_vz_54790000 t_vz_54790000 4017 532\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o merge das colunas de vazão que são correspondentes à mesma estação\n",
    "# Acontece que existem gaps entre os dados, o que é estranho, porque a estação telemétrica tem dados que a convencional não tem e vice-versa.\n",
    "# Vou contar qual coluna tem mais dados e depois executar um 'fillna'\n",
    "\n",
    "colunas_esquerda = ['c_cv_54790000', 'c_vz_54790000']\n",
    "colunas_direita = ['t_cv_54790000', 't_vz_54790000']\n",
    "\n",
    "for i, j in zip(colunas_esquerda, colunas_direita):\n",
    "    print(i, j, df[i].isna().sum(), df[j].isna().sum())\n",
    "\n",
    "# A coluna que tiver menos buracos será preenchida com os dados da coluna que tem mais dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preenchendo a coluna que tem menos dados faltantes com a outra correspondente\n",
    "# # Fazer isso para cada coluna, contudo, tem colunas que tem dados faltando demais. Neste caso, darei drop nelas inteiramente.\n",
    "# df['c_vz_56994500'].fillna(df['t_vz_56994500'], inplace=True)\n",
    "# df['t_vz_56990850'].fillna(df['c_vz_56990850'], inplace=True)\n",
    "# df['t_vz_56990005'].fillna(df['c_vz_56990005'], inplace=True)\n",
    "\n",
    "# df['c_vz_56994500'].isna().sum(), df['t_vz_56990850'].isna().sum(), df['t_vz_56990005'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_cv_01640007</th>\n",
       "      <th>c_cv_01640000</th>\n",
       "      <th>t_cv_54790000</th>\n",
       "      <th>t_vz_54790000</th>\n",
       "      <th>c_vz_54780000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.450000</td>\n",
       "      <td>442.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.420833</td>\n",
       "      <td>131.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>117.235417</td>\n",
       "      <td>121.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.239583</td>\n",
       "      <td>93.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.920833</td>\n",
       "      <td>97.8542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_cv_01640007  c_cv_01640000  t_cv_54790000  t_vz_54790000  \\\n",
       "Data                                                                     \n",
       "2013-01-01            NaN            0.6            NaN            NaN   \n",
       "2013-01-02            NaN            0.0            NaN            NaN   \n",
       "2013-01-03            NaN           13.2            NaN            NaN   \n",
       "2013-01-04            NaN            0.0            NaN            NaN   \n",
       "2013-01-05            NaN            0.0            NaN            NaN   \n",
       "...                   ...            ...            ...            ...   \n",
       "2023-12-27            NaN            0.0            0.0     211.450000   \n",
       "2023-12-28            NaN            0.0            0.0     167.420833   \n",
       "2023-12-29            NaN            0.0            0.6     117.235417   \n",
       "2023-12-30            NaN            0.0            0.0      94.239583   \n",
       "2023-12-31            NaN            7.5            0.0     103.920833   \n",
       "\n",
       "            c_vz_54780000  \n",
       "Data                       \n",
       "2013-01-01       187.7730  \n",
       "2013-01-02       105.3130  \n",
       "2013-01-03       101.8800  \n",
       "2013-01-04        98.5206  \n",
       "2013-01-05        98.5206  \n",
       "...                   ...  \n",
       "2023-12-27       442.6400  \n",
       "2023-12-28       131.6670  \n",
       "2023-12-29       121.8540  \n",
       "2023-12-30        93.7937  \n",
       "2023-12-31        97.8542  \n",
       "\n",
       "[4017 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estas colunas estão completamente vazias:\n",
    "# c_cv_54790000\n",
    "# c_vz_54790000\n",
    "# Vou remover ambas\n",
    "\n",
    "df = df.drop(columns=[\"c_cv_54790000\", \"c_vz_54790000\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de NaN por coluna\n",
      "c_cv_01640007    4017\n",
      "c_cv_01640000       0\n",
      "t_cv_54790000     273\n",
      "t_vz_54790000     532\n",
      "c_vz_54780000     564\n",
      "dtype: int64\n",
      "Percentual de NaN por coluna\n",
      "c_cv_01640007 100.0\n",
      "c_cv_01640000 0.0\n",
      "t_cv_54790000 6.796116504854369\n",
      "t_vz_54790000 13.243714214588001\n",
      "c_vz_54780000 14.0403286034354\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de valores \"NaN\" em cada coluna\n",
    "\n",
    "print(\"Quantidade de NaN por coluna\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"Percentual de NaN por coluna\")\n",
    "for c in np.asarray(df.columns):\n",
    "    print(c, (df[c].isna().sum()/len(df))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_cv_01640000</th>\n",
       "      <th>t_cv_54790000</th>\n",
       "      <th>t_vz_54790000</th>\n",
       "      <th>c_vz_54780000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.450000</td>\n",
       "      <td>442.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.420833</td>\n",
       "      <td>131.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>117.235417</td>\n",
       "      <td>121.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.239583</td>\n",
       "      <td>93.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.920833</td>\n",
       "      <td>97.8542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_cv_01640000  t_cv_54790000  t_vz_54790000  c_vz_54780000\n",
       "Data                                                                  \n",
       "2013-01-01            0.6            NaN            NaN       187.7730\n",
       "2013-01-02            0.0            NaN            NaN       105.3130\n",
       "2013-01-03           13.2            NaN            NaN       101.8800\n",
       "2013-01-04            0.0            NaN            NaN        98.5206\n",
       "2013-01-05            0.0            NaN            NaN        98.5206\n",
       "...                   ...            ...            ...            ...\n",
       "2023-12-27            0.0            0.0     211.450000       442.6400\n",
       "2023-12-28            0.0            0.0     167.420833       131.6670\n",
       "2023-12-29            0.0            0.6     117.235417       121.8540\n",
       "2023-12-30            0.0            0.0      94.239583        93.7937\n",
       "2023-12-31            7.5            0.0     103.920833        97.8542\n",
       "\n",
       "[4017 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta coluna está completamente vazia:\n",
    "# c_cv_01640007\n",
    "# Vou remover\n",
    "\n",
    "df = df.drop(columns=[\"c_cv_01640007\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_cv_01640000</th>\n",
       "      <th>t_cv_54790000</th>\n",
       "      <th>t_vz_54790000</th>\n",
       "      <th>c_vz_54780000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.450000</td>\n",
       "      <td>442.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.420833</td>\n",
       "      <td>131.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>117.235417</td>\n",
       "      <td>121.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.239583</td>\n",
       "      <td>93.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.920833</td>\n",
       "      <td>97.8542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4017 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_cv_01640000  t_cv_54790000  t_vz_54790000  c_vz_54780000\n",
       "Data                                                                  \n",
       "2013-01-01            0.6            NaN            NaN       187.7730\n",
       "2013-01-02            0.0            NaN            NaN       105.3130\n",
       "2013-01-03           13.2            NaN            NaN       101.8800\n",
       "2013-01-04            0.0            NaN            NaN        98.5206\n",
       "2013-01-05            0.0            NaN            NaN        98.5206\n",
       "...                   ...            ...            ...            ...\n",
       "2023-12-27            0.0            0.0     211.450000       442.6400\n",
       "2023-12-28            0.0            0.0     167.420833       131.6670\n",
       "2023-12-29            0.0            0.6     117.235417       121.8540\n",
       "2023-12-30            0.0            0.0      94.239583        93.7937\n",
       "2023-12-31            7.5            0.0     103.920833        97.8542\n",
       "\n",
       "[4017 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deixando os dados contínuos, numa base diária.\n",
    "df = df.resample('D').first()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neste momento, tenho o DataFrame com os dados EXATAMENTE da forma que preciso.\n",
    "# Posso, inclusive, exportar isso para um arquivo de Excel\n",
    "# É o que farei, pois se precisar retornar aos dados originais, será mais fácil que fazer toda engenharia até aqui\n",
    "\n",
    "df.to_excel('./arquivo_final/baixo_rio_jequitinhonha_final.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertacao_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
